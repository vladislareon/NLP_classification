{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dbb20980",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbb20980",
        "outputId": "868b2be7-7100-4011-973b-74d3a643cda6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Over $616 million in Bitcoin was electrocated ...\n",
              "1                            Quiz: Thursday or friday?\n",
              "2    The Australian Revenue Authority will start co...\n",
              "3     Let's continue😉. I present to you my new review \n",
              "4                      Here comes your future palette.\n",
              "Name: message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lxml import html\n",
        "import requests\n",
        "#from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train_all1 = pd.read_csv('train_data.csv')['message']\n",
        "y_train_all = pd.read_csv('train_solution.csv')['category']\n",
        "X_train_all1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "103b5ef1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "103b5ef1",
        "outputId": "9af9ffdb-9d50-4ba1-bf7b-d6c295be20b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3844,)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "X_train_all1.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = 'You can make any creamy lipstick look matte with loose powder and a tissue. Simply fill in your lips with your desired color, place a tissue over the lipstick and brush the powder along the tissue. The powder soaks up the shine and gives your favorite lipstick a smooth, matte finish.'\n",
        "d1 = 'After you finish painting your nails, submerge your hands in ice water to help them dry faster.'\n",
        "d3 = 'Store makeup wipes upside down (with the opening facing down) to keep them from drying out. According to makeup artist Kelli Bartlett, this will help the product thoroughly soak through every towelette, starting with the one you’re going to use next. We love the CeraVe Hydrating Makeup Removing Plant-Based Wipes.'\n",
        "d5 = 'To master the perfect everyday winged eyeliner, start your line at the outer corner of your eyelid. Then, once you have your desired length, begin to fill in the wing. This is easier than carrying the line through to the inner corner of your eye. An editor favorite is the NYX Professional Makeup Epic Ink Liner.'\n",
        "\n",
        "d6 = 'Cosmetics designed for skin care can be used to cleanse, exfoliate and protect the skin, as well as replenishing it, through the use of cleansers, toners, serums, moisturizers, and balms. Cosmetics designed for more general personal care, such as shampoo and body wash, can be used to cleanse the body.Cosmetics designed to enhance ones appearance (makeup) can be used to conceal blemishes, enhance one`s natural features (such as the eyebrows and eyelashes), add color to a person`s face and—in the case of more extreme forms of makeup used for performances, fashion shows and people in costume—can be used to change the appearance of the face entirely to resemble a different person, creature or object. Techniques for changing appearance include contouring, which aims to give shape to an area of the face.Cosmetics can also be designed to add fragrance to the body.'\n"
      ],
      "metadata": {
        "id": "sf1GcgSmfJ4w"
      },
      "id": "sf1GcgSmfJ4w",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 'Cryptocurrencies have gone from a curiosity to a sizable force in finance, technology and culture, making them almost impossible to ignore. A range of players have embraced crypto, from individual speculators to major financial institutions, despite how volatile they are..  Some have generated vast riches, while others have destroyed huge amounts of wealth.When people talk about crypto, they may be referring to one of many different ideas and companies. The industry is booming and spawning an abundance of projects and new terms to go with them. The topic can be confusing, but the concept has also become ubiquitous. Learning the right terminology can help.'\n",
        "b = 'A Bitcoin is a digital token that can be sent electronically from one user to another, anywhere in the world.A Bitcoin can be divided out to eight decimal places, so you can send someone 0.00000001 Bitcoin. This smallest fraction of a Bitcoin — the penny of the Bitcoin world — is referred to as a Satoshi, named after the pseudonymous creator of Bitcoin.Bitcoin is also the name of the payment network on which this form of digital currency is stored and moved. Unlike traditional payment networks such as Visa, the Bitcoin network is not run by a single company or person. The system is run by a decentralized network of computers around the world that keep track of all Bitcoin transactions, similar to the way Wikipedia is maintained by a decentralized network of writers and editors.'\n",
        "c = 'Bitcoin was introduced in 2008 by a creator who goes by the name Satoshi Nakamoto, who communicated with the rest of the world only by email and social messaging. While several people have been identified as possibly being Satoshi, the identity of the real Satoshi has not been confirmed.Satoshi created the original rules of the Bitcoin network and then shared the software with the rest of the world in 2009. The inventor largely disappeared from the public two years later. Once Satoshi had released the software, anyone could download and use it. This means Satoshi has no more control over the network now than anyone else.'\n",
        "d = 'The original blockchain was the database on which all Bitcoin transactions were stored. It was named “blockchain” because the transactions coming onto the network were grouped into blocks of data and then chained together using sophisticated math.After the Bitcoin blockchain had operated for a number of years, successfully storing every Bitcoin transaction and surviving numerous attacks from hackers, many programmers and entrepreneurs wondered if its design could be replicated to create other kinds of secure ledgers unrelated to Bitcoin.'"
      ],
      "metadata": {
        "id": "NmyUjxAEXGxM"
      },
      "id": "NmyUjxAEXGxM",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cosmetics.txt') as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "XV0SThnWlzKG"
      },
      "id": "XV0SThnWlzKG",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['mes'] = str(lines).split('\\\\n')\n",
        "df['mes'] = df['mes'].apply(lambda x: x.replace('\"', '').replace('[', '').replace('', '').replace(',', '').replace(\"'\", ''))"
      ],
      "metadata": {
        "id": "ZCfdfEw-l3Bm"
      },
      "id": "ZCfdfEw-l3Bm",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame()\n",
        "df1['mes'] = [a, b, c, d]\n",
        "df =  pd.concat([df['mes'] , df1['mes'] ], ignore_index=True)"
      ],
      "metadata": {
        "id": "G0AsKzWLXN9H"
      },
      "id": "G0AsKzWLXN9H",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2c1caab2",
      "metadata": {
        "id": "2c1caab2"
      },
      "outputs": [],
      "source": [
        "def get_df(name):\n",
        "    with open(f'{name}', \"r\", encoding=\"utf8\") as f:\n",
        "        page = f.read()\n",
        "    tree = html.fromstring(page)\n",
        "    crypto = str(tree.text_content()).split('\\n\\n')\n",
        "    crypto = [item.replace('\\n', '') for item in crypto if len(item.split(' '))  >= 3]\n",
        "    crypto = [item.replace('\\n', '') for item in crypto if item  != '          Not included, change data exporting settings to download.          ']\n",
        "    crypto = [item for item in crypto if 'https' not in item ]\n",
        "    cr = pd.DataFrame()\n",
        "    cr['mes'] = crypto\n",
        "    return cr.iloc[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "17ecd69f",
      "metadata": {
        "id": "17ecd69f"
      },
      "outputs": [],
      "source": [
        "student_chat = get_df('messages.html')\n",
        "for i in range(2, 17):\n",
        "    student_chat = pd.concat([get_df(f'messages{i}.html'), student_chat], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def contains_number(string):\n",
        "    return any(char.isdigit() for char in string)\n",
        "def get_df_beauty(name):\n",
        "    with open(f'{name}', \"r\", encoding=\"utf8\") as f:\n",
        "        page = f.read()\n",
        "    tree = html.fromstring(page)\n",
        "    crypto = str(tree.text_content()).split('\\n\\n')\n",
        "    crypto = [item.replace('\\n', '') for item in crypto if len(item.split(' ')) >= 3]\n",
        "    crypto = [item for item in crypto if contains_number(item) == False]\n",
        "    crypto = [item for item in crypto if 'https' not in item ]\n",
        "    crypto = [item for item in crypto if item[-1]  != 'B']\n",
        "    crypto = [item.replace('\\n', '') for item in crypto if item  != '       In Voga | Fashion & Web 3.0        ' ]\n",
        "    crypto = [item.replace('\\n', '') for item in crypto if item  != '          Not included, change data exporting settings to download.          ']\n",
        "    crypto = [item for item in crypto if 'https' not in item ]\n",
        "    cr = pd.DataFrame()\n",
        "    cr['mes'] = crypto\n",
        "    return cr.iloc[1:]"
      ],
      "metadata": {
        "id": "cPunmALrO0DY"
      },
      "id": "cPunmALrO0DY",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beauty_new = get_df_beauty('messages17.html')\n",
        "for i in range(18, 21):\n",
        "    beauty_new = pd.concat([get_df(f'messages{i}.html'), beauty_new], ignore_index=True)"
      ],
      "metadata": {
        "id": "jNOLLsdgOF8N"
      },
      "id": "jNOLLsdgOF8N",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_1 = get_df('crmessages.html')\n",
        "for i in range(2, 11):\n",
        "    crypto_1 = pd.concat([get_df(f'crmessages{i}.html'), crypto_1], ignore_index=True)"
      ],
      "metadata": {
        "id": "OZfJ0diFIpx4"
      },
      "id": "OZfJ0diFIpx4",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "29e5c45c",
      "metadata": {
        "id": "29e5c45c"
      },
      "outputs": [],
      "source": [
        "with open('crypto.html', \"r\", encoding=\"utf8\") as f:\n",
        "    page = f.read()\n",
        "tree = html.fromstring(page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cc6b1fba",
      "metadata": {
        "id": "cc6b1fba"
      },
      "outputs": [],
      "source": [
        "crypto = str(tree.text_content()).split('\\n\\n')\n",
        "crypto = [item.replace('\\n', '') for item in crypto if len(item.split(' ')) >= 3]\n",
        "cr = pd.DataFrame()\n",
        "cr['mes'] = crypto\n",
        "crypto =  pd.concat([cr, crypto_1], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "897de672",
      "metadata": {
        "id": "897de672"
      },
      "outputs": [],
      "source": [
        "def contains_number(string):\n",
        "    return any(char.isdigit() for char in string)\n",
        "with open('beauty1.html', \"r\", encoding=\"utf8\") as f:\n",
        "    page = f.read()\n",
        "tree1 = html.fromstring(page)\n",
        "with open('beauty2.html', \"r\", encoding=\"utf8\") as f:\n",
        "    page = f.read()\n",
        "tree2 = html.fromstring(page)\n",
        "beauty1 = str(tree1.text_content()).split('\\n\\n')\n",
        "#beauty1 = [item for item in beauty1 if len(item) >40]\n",
        "beauty1 = [item.replace('\\n', '') for item in beauty1 if len(item.split(' ')) >= 3]\n",
        "beauty1 = [item for item in beauty1 if contains_number(item) == False]\n",
        "beauty1 = [item for item in beauty1 if 'https' not in item ]\n",
        "bea1 = pd.DataFrame()\n",
        "bea1['mes'] = beauty1\n",
        "beauty2 = str(tree2.text_content()).split('\\n\\n')\n",
        "beauty2 = [item for item in beauty2 if len(item) >40]\n",
        "beauty2 = [item.replace('\\n', '') for item in beauty2 if len(item) >40]\n",
        "beauty1 = [item for item in beauty2 if contains_number(item) == False]\n",
        "beauty2 = [item for item in beauty2 if 'https' not in item ]\n",
        "bea2 = pd.DataFrame()\n",
        "bea2['mes'] = beauty2\n",
        "beauty = pd.concat([bea1, bea2], ignore_index=True).iloc[1:-1]\n",
        "beauty = pd.concat([beauty_new, beauty], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4d41318b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d41318b",
        "outputId": "9292a183-92eb-4a13-d4af-e046147d218f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1428\n",
              "2    1217\n",
              "1    1199\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train_all.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "96b8cb05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b8cb05",
        "outputId": "aef41344-f3df-46c3-87f6-8b6be36b7c79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         But a lot of people have a job fair tonight.\n",
              "1    Also, I got only 4 answers on the google form ...\n",
              "2                 Vladimir, when will we have seminar?\n",
              "3                                A couple at 111, too?\n",
              "4                It's on Anti-buying. And again, Zara:\n",
              "Name: message, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_test_all1 = pd.read_csv('test_data.csv')['message']\n",
        "test_id = pd.read_csv('test_data.csv')['id']\n",
        "X_test_all1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bb83d7a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb83d7a5",
        "outputId": "a4647c5e-1c91-4262-9176-a607ed3cbc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    return [word for word in word_tokenize(text.lower()) if word not in string.punctuation]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "830a5584",
      "metadata": {
        "id": "830a5584"
      },
      "outputs": [],
      "source": [
        "X_train_all = X_train_all1.apply(process_text)\n",
        "X_test_all = X_test_all1.apply(process_text)\n",
        "crypto = crypto['mes'].apply(process_text)\n",
        "beauty = beauty['mes'].apply(process_text)\n",
        "df = df.apply(process_text)\n",
        "student_chat = student_chat['mes'].apply(process_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.DataFrame()\n",
        "new['txt'] = X_train_all\n",
        "new['t'] = y_train_all"
      ],
      "metadata": {
        "id": "mhBchxORKCH1"
      },
      "id": "mhBchxORKCH1",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0bc7a2e7",
      "metadata": {
        "id": "0bc7a2e7"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import multiprocessing\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "98cb4837",
      "metadata": {
        "id": "98cb4837"
      },
      "outputs": [],
      "source": [
        "all_data = pd.concat([X_train_all, X_test_all, crypto, beauty, student_chat, df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a062d224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a062d224",
        "outputId": "da1545c4-04fe-4cd9-a6de-0981d5081921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31276540, 40059600)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "model_w2w = Word2Vec(all_data, min_count=1, size = 1000, window=5)\n",
        "model_w2w.build_vocab(all_data, update=True)\n",
        "model_w2w.train(all_data, epochs=35, total_examples=model_w2w.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw8K6mlYvEJq",
        "outputId": "b274e075-c687-4e84-dd45-6df9e7c685f0"
      },
      "id": "cw8K6mlYvEJq",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [over, million, in, bitcoin, was, electrocated...\n",
              "1                              [quiz, thursday, or, friday]\n",
              "2         [the, australian, revenue, authority, will, st...\n",
              "3         [let, continue, present, to, you, my, new, rev...\n",
              "4                      [here, comes, your, future, palette]\n",
              "                                ...                        \n",
              "435527                                                   []\n",
              "435528    [cryptocurrencies, have, gone, from, curiosity...\n",
              "435529    [a, bitcoin, is, digital, token, that, can, be...\n",
              "435530    [bitcoin, was, introduced, in, by, creator, wh...\n",
              "435531    [the, original, blockchain, was, the, database...\n",
              "Length: 435532, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1beb74a6",
      "metadata": {
        "id": "1beb74a6"
      },
      "outputs": [],
      "source": [
        "def w2vec(model, all_sent):\n",
        "    vect1 = []\n",
        "    for senten in all_sent:\n",
        "        if len(senten) != 0:\n",
        "            now_vect = [0] * model.vector_size\n",
        "            for word in senten:\n",
        "                now_vect += model.wv.get_vector(word)\n",
        "            vect1.append(now_vect / len(senten))      \n",
        "        else:\n",
        "            vect1.append([0] * model.vector_size)\n",
        "    return vect1\n",
        "def w2vec_tf_idf(model, all_sent):\n",
        "    vect1 = []\n",
        "    for senten in all_sent:\n",
        "        if len(senten) != 0:\n",
        "            now_vect = [0] * model.vector_size\n",
        "            for word in senten:\n",
        "               # print(word)\n",
        "                now_vect += model.wv.get_vector(word) * idf[word]\n",
        "            vect1.append(now_vect / len(senten))      \n",
        "        else:\n",
        "            vect1.append([0] * model.vector_size)\n",
        "    return vect1"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GK_BJ3ZZYpfZ"
      },
      "id": "GK_BJ3ZZYpfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My future:"
      ],
      "metadata": {
        "id": "2k-n0yq0YqPu"
      },
      "id": "2k-n0yq0YqPu"
    },
    {
      "cell_type": "code",
      "source": [
        "fut = process_text('my future')\n",
        "future1 = w2vec(model_w2w, [fut])[0]"
      ],
      "metadata": {
        "id": "Mo_TcvjW-EJZ"
      },
      "id": "Mo_TcvjW-EJZ",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, sim in model_w2w.most_similar(positive=[future1], topn=10):\n",
        "   print(f'{word} : {sim}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEq8AtrJ_uHw",
        "outputId": "3fb0dac0-92ec-4e50-80ab-3493a38269ca"
      },
      "id": "aEq8AtrJ_uHw",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my : 0.7681654691696167\n",
            "future : 0.5247399806976318\n",
            "circus : 0.3384133577346802\n",
            "your : 0.3367308974266052\n",
            "myself : 0.32697856426239014\n",
            "faint : 0.3202984929084778\n",
            "his : 0.3142862617969513\n",
            "marilyn : 0.31344226002693176\n",
            "fan : 0.3043716549873352\n",
            "wealthy : 0.30159223079681396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ae523394",
      "metadata": {
        "id": "ae523394"
      },
      "outputs": [],
      "source": [
        "vect_train = w2vec(model_w2w, X_train_all)\n",
        "vect_test = w2vec(model_w2w, X_test_all)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(future1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpKded8IXy2u",
        "outputId": "d1213bbd-f520-45f5-ebff-54ef5d443639"
      },
      "id": "OpKded8IXy2u",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "neig = NearestNeighbors().fit(vect_train)\n",
        "it = neig.kneighbors([list(future1)], 3, return_distance=False)[0]\n",
        "print(X_train_all1.iloc[it])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ2m5zGLWvJN",
        "outputId": "f3572fd3-3f70-4430-fe0a-8d680999302a"
      },
      "id": "EJ2m5zGLWvJN",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1039                oh my\n",
            "1382    ♪ try my plough ♪\n",
            "2261          Oh, my God.\n",
            "Name: message, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Получим предсказания для соревнования при помощи бустинга:"
      ],
      "metadata": {
        "id": "2JbAFzLPYwiz"
      },
      "id": "2JbAFzLPYwiz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406b4c63",
      "metadata": {
        "id": "406b4c63"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "clf = CatBoostClassifier(logging_level='Silent')\n",
        "clf.fit(vect_train, y_train_all)\n",
        "y_pred = clf.predict(vect_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc4cca0",
      "metadata": {
        "id": "4bc4cca0"
      },
      "outputs": [],
      "source": [
        "answer = pd.DataFrame()\n",
        "answer['id'] = test_id\n",
        "answer['category'] = y_pred\n",
        "answer = answer.reset_index(drop=True)\n",
        "answer.to_csv('w2w_17.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5uGi-NvhY6HN"
      },
      "id": "5uGi-NvhY6HN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эскперименты со сверточной нейронной сетью:"
      ],
      "metadata": {
        "id": "z634q-2mY63W"
      },
      "id": "z634q-2mY63W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945b98e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945b98e7",
        "outputId": "8f2693d5-533c-4171-c2dd-b810aa6f2557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.9\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision\n",
        "!pip install torchtext==0.9\n",
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07df7cad",
      "metadata": {
        "id": "07df7cad"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce767397",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce767397",
        "outputId": "24864cda-9fce-4d38-bb5c-d08245750f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3844\n",
            "5927\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train_all))\n",
        "print(len(X_test_all))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import data\n",
        "# data.Field is obsolete now\n",
        "from torchtext.legacy import data"
      ],
      "metadata": {
        "id": "TOI1wdiIws-w"
      },
      "id": "TOI1wdiIws-w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.DataFrame()\n",
        "new['txt'] = pd.read_csv('train_data.csv')['message']\n",
        "new['t'] = y_train_all.apply(int)\n",
        "new = new.reset_index(drop=True)\n",
        "new.to_csv('data.csv', index=False)\n",
        "new = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "RCd2rupDF9-k"
      },
      "id": "RCd2rupDF9-k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Field and LabelField classes are responsible for the way data will be stored and processed\n",
        "TEXT = data.Field(tokenize = process_text) # we'll use spacy for tokenization here\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "ds = data.TabularDataset(\n",
        "  path='data.csv', format='csv',\n",
        "  skip_header=True,\n",
        "  fields=[('text', TEXT),\n",
        "        ('label', LABEL)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "qx1TYJ73F9Nt"
      },
      "id": "qx1TYJ73F9Nt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import Vectors\n",
        "#vectors = Vectors(model.wv.vectors) \n",
        "TEXT.build_vocab(ds, min_freq=1)\n",
        "LABEL.build_vocab(ds)"
      ],
      "metadata": {
        "id": "8Szr7vz5F9Qc"
      },
      "id": "8Szr7vz5F9Qc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_vectors = []\n",
        "for token, idx in tqdm_notebook(TEXT.vocab.stoi.items()):\n",
        "    if token in model_w2w.wv.vocab.keys():\n",
        "        word2vec_vectors.append(torch.FloatTensor(model_w2w.wv.get_vector(token)))\n",
        "    else:\n",
        "        word2vec_vectors.append(torch.zeros(300))\n",
        "TEXT.vocab.set_vectors(TEXT.vocab.stoi, word2vec_vectors, 300)\n",
        "LABEL.build_vocab(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0288a18e451647959776f2c349b3ebbe",
            "8f2e572404f742f79d4179d59fec8fd4",
            "7fd9a1beb60d41779418516b3611118c",
            "1f49eaf517be45bea0af43116d042b02",
            "53ad112f46b8436bb2b82b83e1891336",
            "8caf6e0f09444d9985c7b4da071aef12",
            "1785e1a1e5494cfd9d191c46f58fccab",
            "cfc875e092f749aaa37dcc82b95a02b7",
            "b847d11536ec4401bf1e794c21387a25",
            "801f1f0fd0ca4c30b72ea0e28246b952",
            "22b53fa201bc4ae4b02e477911ecc756"
          ]
        },
        "id": "_mnf5Fj59nQt",
        "outputId": "3e246d31-9d0d-4c5d-c418-24169a7d2c63"
      },
      "id": "_mnf5Fj59nQt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/18413 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0288a18e451647959776f2c349b3ebbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds, val = ds.split(split_ratio = 0.8, stratified=True) "
      ],
      "metadata": {
        "id": "1-w6XBQzSya-"
      },
      "id": "1-w6XBQzSya-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4qgrFhvTByz"
      },
      "id": "V4qgrFhvTByz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmNgbATLJD3C"
      },
      "id": "wmNgbATLJD3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_emb = torch.FloatTensor(TEXT.vocab.vectors)\n",
        "embedding = nn.Embedding.from_pretrained(pre_trained_emb)\n",
        "pre_trained_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xu7MsJMI5If",
        "outputId": "4ec11cfd-0023-4b65-c3c6-dced1ef2c3b2"
      },
      "id": "1xu7MsJMI5If",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.3566, -0.6318,  1.1310,  ...,  0.5018, -0.9287,  0.2305],\n",
              "        ...,\n",
              "        [ 0.0282,  0.0392, -0.0208,  ..., -0.0939, -0.1029, -0.1234],\n",
              "        [-0.0990, -0.0777,  0.1080,  ..., -0.1753, -0.1727, -0.1310],\n",
              "        [-0.0608,  0.0817,  0.3223,  ..., -0.0119, -0.1826, -0.2394]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 500\n",
        "\n",
        "train_iterator, val_iterator = data.BucketIterator.splits(\n",
        "    (ds, val), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    sort=True,\n",
        "    sort_key=lambda x: len(x.text), # sort texts by length so that there are sentences with the same length next to each other and less padding is added\n",
        "    shuffle = True,\n",
        "    repeat=False)"
      ],
      "metadata": {
        "id": "nzVAv2NsJlUu"
      },
      "id": "nzVAv2NsJlUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyaji4kNLOcA",
        "outputId": "bf72aacf-26bc-427c-cb24-b097249e9bb6"
      },
      "id": "Vyaji4kNLOcA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0': 0, '2': 1, '1': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx43UusdMb1t",
        "outputId": "a33f4440-480f-4338-9194-34b1b8b877bd"
      },
      "id": "Dx43UusdMb1t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0': 0, '2': 1, '1': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Um7Ql8fAMozH"
      },
      "id": "Um7Ql8fAMozH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ku2aCB0LMo6Z"
      },
      "id": "Ku2aCB0LMo6Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout_proba):\n",
        "        super().__init__()\n",
        "        self.n_filters = n_filters\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)        \n",
        "        self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "        self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, 3)\n",
        "        self.dropout = nn.Dropout(dropout_proba)\n",
        "        self.conv_new_1  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(1, embedding_dim))\n",
        "        self.conv_new_2  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(2, embedding_dim))\n",
        "        self.conv_new_3  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(3, embedding_dim))\n",
        "        self.conv_new_4  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(4, embedding_dim))\n",
        "        self.conv_new_6  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(6, embedding_dim))\n",
        "        self.conv_new_7  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(7, embedding_dim))\n",
        "        self.conv_new_8  = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(8, embedding_dim))\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #x = [sent len, batch size]\n",
        "        x = x.permute(1, 0)\n",
        "                \n",
        "        #x = [batch size, sent len]\n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        if embedded.shape[2] == 1:\n",
        "          conved_0 = F.relu(self.conv_new_1(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_new_1(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_new_1(embedded).squeeze(3))\n",
        "        elif embedded.shape[2] == 2:\n",
        "          conved_0 = F.relu(self.conv_new_1(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_new_2(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_new_2(embedded).squeeze(3))\n",
        "        elif embedded.shape[2] == 3:\n",
        "          conved_0 = F.relu(self.conv_new_1(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_new_2(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_new_3(embedded).squeeze(3))\n",
        "        elif embedded.shape[2] == 4:\n",
        "          conved_0 = F.relu(self.conv_new_2(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_new_3(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_new_4(embedded).squeeze(3))\n",
        "        elif embedded.shape[2] >= 8:\n",
        "          conved_0 = F.relu(self.conv_new_6(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_new_7(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_new_7(embedded).squeeze(3))\n",
        "\n",
        "        else:\n",
        "          #embedded = [batch size, 1, sent len, emb dim]\n",
        "          conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "          conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "          conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "        \n",
        "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
        "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
        "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
        "        \n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
        "\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "        return self.fc(cat)"
      ],
      "metadata": {
        "id": "EHqpC-AWMo-M"
      },
      "id": "EHqpC-AWMo-M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "M_hwdvO3Mq2N"
      },
      "id": "M_hwdvO3Mq2N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_func(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = accuracy_score(predictions.argmax(1), batch.label)\n",
        "        #acc = (predictions.argmax(1) == batch.label.detach().numpy()).mean()\n",
        "        #acc = accuracy_score(torch.round(torch.sigmoid(predictions.float())).detach().numpy(), batch.label.detach().numpy())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss\n",
        "        epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "R9fyUjKLMyD2"
      },
      "id": "R9fyUjKLMyD2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_func(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = accuracy_score(predictions.argmax(1), batch.label)\n",
        "\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "A2G9Zq9hefIQ"
      },
      "id": "A2G9Zq9hefIQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 600\n",
        "N_FILTERS = 200\n",
        "FILTER_SIZES =  [3,4,5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT_PROBA = 0.5\n",
        "\n",
        "model_cnn = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT_PROBA)"
      ],
      "metadata": {
        "id": "OL4GDaqoM_JC"
      },
      "id": "OL4GDaqoM_JC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings =  torch.FloatTensor(TEXT.vocab.vectors)\n",
        "model_cnn.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "254YehQ2NIc2",
        "outputId": "17721fba-ce31-41fe-89e9-60d759f02e41"
      },
      "id": "254YehQ2NIc2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-13b8a60427be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpretrained_embeddings\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (600) must match the size of tensor b (300) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "nBM4eX6uNLjP"
      },
      "id": "nBM4eX6uNLjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model_cnn.parameters()) # we have given all parameters to the optimizer, so embeddigs will also be fitted\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "#model_cnn = model_cnn.cuda() # we will train on gpu! =)"
      ],
      "metadata": {
        "id": "T2wDWGs5UPcW"
      },
      "id": "T2wDWGs5UPcW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def force_cudnn_initialization():\n",
        "#     s = 32\n",
        "#     dev = torch.device('cuda')\n",
        "#     torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
      ],
      "metadata": {
        "id": "m7cYAtecYgMi"
      },
      "id": "m7cYAtecYgMi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 25\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train_func(model_cnn, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate_func(model_cnn, val_iterator, criterion)\n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "Feg1tzZKUPpG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "4ae52c4b-195f-4128-ff39-b518c64ca50b"
      },
      "id": "Feg1tzZKUPpG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train Loss: 1.581, Train Acc: 54.15%, Val. Loss: 0.971, Val. Acc: 58.14%\n",
            "Epoch: 02, Train Loss: 1.105, Train Acc: 69.06%, Val. Loss: 0.542, Val. Acc: 80.03%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9d5f1cdf6ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:.3f}, Val. Acc: {valid_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-12f1da708817>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#acc = accuracy_score(torch.round(torch.sigmoid(predictions.float())).detach().numpy(), batch.label.detach().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.DataFrame()\n",
        "new['txt'] = pd.read_csv('test_data.csv')['message']\n",
        "new = new.reset_index(drop=True)\n",
        "new.to_csv('test_new.csv', index=False)\n",
        "new = pd.read_csv('test_new.csv')"
      ],
      "metadata": {
        "id": "1sMSXJgb1eBB"
      },
      "id": "1sMSXJgb1eBB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Field and LabelField classes are responsible for the way data will be stored and processed\n",
        "TEXT_test = data.Field(tokenize = process_text) # we'll use spacy for tokenization here\n",
        "\n",
        "ds_test = data.TabularDataset(\n",
        "  path='test_new.csv', format='csv',\n",
        "  skip_header=True,\n",
        "  fields=[('text', TEXT_test)]\n",
        ")\n",
        "#vectors = Vectors(model.wv.vectors) \n",
        "TEXT_test.build_vocab(ds_test, min_freq=1)\n",
        "word2vec_vectors = []\n",
        "for token, idx in tqdm_notebook(TEXT_test.vocab.stoi.items()):\n",
        "    if token in model_w2w.wv.vocab.keys():\n",
        "        word2vec_vectors.append(torch.FloatTensor(model_w2w.wv.get_vector(token)))\n",
        "    else:\n",
        "        word2vec_vectors.append(torch.zeros(300))\n",
        "TEXT_test.vocab.set_vectors(TEXT_test.vocab.stoi, word2vec_vectors, 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8a6ce88cd4084ed69ae60e37910bf4dd",
            "7009fe04bc72422888919f21e4882dbf",
            "652cfe5e494745bcaa34885c47ce4a61",
            "c76a71d49d5d42c6bca8867959f64dee",
            "a5e3f8611e4747998c5d6a65b17ebbf8",
            "6746bef5fdd54c038f7864b2636393db",
            "2fd8d0a3d6bc483dbc23806ca424bd8e",
            "91d9c6853d3b4e128ba0b7c8eab41309",
            "7adc26644ff844a88dd9fdc8d7c3231d",
            "911cf8333443403db63939a0d81dbb9b",
            "e2cdbf346fa244d3b53200ae400c5c98"
          ]
        },
        "id": "eD_tQSGarHQv",
        "outputId": "b675de0a-9894-4e1d-b732-3fe5b97421c1"
      },
      "id": "eD_tQSGarHQv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17874 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a6ce88cd4084ed69ae60e37910bf4dd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 500\n",
        "\n",
        "test_iterator = data.BucketIterator(\n",
        "    ds_test, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle = False,\n",
        "    repeat=False)"
      ],
      "metadata": {
        "id": "1V5uQ7WorFxx"
      },
      "id": "1V5uQ7WorFxx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_func(model, iterator):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "              predictions = model(batch.text).squeeze(1)\n",
        "              print(batch.text.shape)\n",
        "              pred = predictions.argmax(1)\n",
        "              y_pred += pred\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "7tEQS_Rp1rP0"
      },
      "id": "7tEQS_Rp1rP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_func(model_cnn, test_iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpuGPy8i6az4",
        "outputId": "dd52d126-00d0-428e-a4c5-dc40d1740947"
      },
      "id": "hpuGPy8i6az4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([433, 500])\n",
            "torch.Size([320, 500])\n",
            "torch.Size([414, 500])\n",
            "torch.Size([305, 500])\n",
            "torch.Size([261, 500])\n",
            "torch.Size([234, 500])\n",
            "torch.Size([328, 500])\n",
            "torch.Size([425, 500])\n",
            "torch.Size([614, 500])\n",
            "torch.Size([596, 500])\n",
            "torch.Size([530, 500])\n",
            "torch.Size([577, 427])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYm7-bO29wiV",
        "outputId": "5501e11e-16f4-4c4b-c7b3-173ef8e937f5"
      },
      "id": "zYm7-bO29wiV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'0': 0, '2': 1, '1': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_new = pd.DataFrame(y_pred).replace({0: {1: 2, 2: 1}})[0].tolist()"
      ],
      "metadata": {
        "id": "xgdA0exq_bik"
      },
      "id": "xgdA0exq_bik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.DataFrame()\n",
        "answer['id'] = test_id\n",
        "answer['category'] = y_pred_new\n",
        "\n",
        "answer = answer.reset_index(drop=True)\n",
        "answer['category'] = answer['category'].apply(lambda x:int(x))\n",
        "answer.to_csv('cnn10.csv', index=False)"
      ],
      "metadata": {
        "id": "rlX4GU7B7EUK"
      },
      "id": "rlX4GU7B7EUK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.DataFrame()\n",
        "answer['id'] = test_id\n",
        "answer['category'] = y_pred\n",
        "answer = answer.reset_index(drop=True)\n",
        "answer.to_csv('cnn3.csv', index=False)"
      ],
      "metadata": {
        "id": "h9fjE6Ff9Dn9"
      },
      "id": "h9fjE6Ff9Dn9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBkrDw4xL0rw"
      },
      "id": "pBkrDw4xL0rw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0288a18e451647959776f2c349b3ebbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f2e572404f742f79d4179d59fec8fd4",
              "IPY_MODEL_7fd9a1beb60d41779418516b3611118c",
              "IPY_MODEL_1f49eaf517be45bea0af43116d042b02"
            ],
            "layout": "IPY_MODEL_53ad112f46b8436bb2b82b83e1891336"
          }
        },
        "8f2e572404f742f79d4179d59fec8fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8caf6e0f09444d9985c7b4da071aef12",
            "placeholder": "​",
            "style": "IPY_MODEL_1785e1a1e5494cfd9d191c46f58fccab",
            "value": "100%"
          }
        },
        "7fd9a1beb60d41779418516b3611118c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc875e092f749aaa37dcc82b95a02b7",
            "max": 18413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b847d11536ec4401bf1e794c21387a25",
            "value": 18413
          }
        },
        "1f49eaf517be45bea0af43116d042b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_801f1f0fd0ca4c30b72ea0e28246b952",
            "placeholder": "​",
            "style": "IPY_MODEL_22b53fa201bc4ae4b02e477911ecc756",
            "value": " 18413/18413 [00:00&lt;00:00, 91494.57it/s]"
          }
        },
        "53ad112f46b8436bb2b82b83e1891336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8caf6e0f09444d9985c7b4da071aef12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1785e1a1e5494cfd9d191c46f58fccab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfc875e092f749aaa37dcc82b95a02b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b847d11536ec4401bf1e794c21387a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "801f1f0fd0ca4c30b72ea0e28246b952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b53fa201bc4ae4b02e477911ecc756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6ce88cd4084ed69ae60e37910bf4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7009fe04bc72422888919f21e4882dbf",
              "IPY_MODEL_652cfe5e494745bcaa34885c47ce4a61",
              "IPY_MODEL_c76a71d49d5d42c6bca8867959f64dee"
            ],
            "layout": "IPY_MODEL_a5e3f8611e4747998c5d6a65b17ebbf8"
          }
        },
        "7009fe04bc72422888919f21e4882dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6746bef5fdd54c038f7864b2636393db",
            "placeholder": "​",
            "style": "IPY_MODEL_2fd8d0a3d6bc483dbc23806ca424bd8e",
            "value": "100%"
          }
        },
        "652cfe5e494745bcaa34885c47ce4a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d9c6853d3b4e128ba0b7c8eab41309",
            "max": 17874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7adc26644ff844a88dd9fdc8d7c3231d",
            "value": 17874
          }
        },
        "c76a71d49d5d42c6bca8867959f64dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911cf8333443403db63939a0d81dbb9b",
            "placeholder": "​",
            "style": "IPY_MODEL_e2cdbf346fa244d3b53200ae400c5c98",
            "value": " 17874/17874 [00:00&lt;00:00, 92585.52it/s]"
          }
        },
        "a5e3f8611e4747998c5d6a65b17ebbf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6746bef5fdd54c038f7864b2636393db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd8d0a3d6bc483dbc23806ca424bd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91d9c6853d3b4e128ba0b7c8eab41309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adc26644ff844a88dd9fdc8d7c3231d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911cf8333443403db63939a0d81dbb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2cdbf346fa244d3b53200ae400c5c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}